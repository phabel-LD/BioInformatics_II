# -*- coding: utf-8 -*-
"""kNN_mushroom_clasification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jWy6r7IiKvyt3dFO9HNl60Ff7fsQ3XKE

# Project: Machine Learning, classify mushrooms by kNN
"""

!python --version

"""## Import Libraries

```
## Code format
```


"""

from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.manifold import TSNE
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import plot_confusion_matrix
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from csv import reader
import numpy as np

## Scikit Version
import sklearn
print(sklearn.__version__)

"""## Explore Data"""

## Read csv file 
mushroom_data = pd.read_csv("agaricus-lepiota.data", header=None, index_col=0)
## Set classes 
mushroom_classes=mushroom_data.index
## Convert to vector
vector_data= np.array(mushroom_data).reshape(mushroom_data.shape[0]*mushroom_data.shape[1],1)
## Create Encoder 
le = preprocessing.LabelEncoder()
## Convert string labels into numbers
vector_encoded=le.fit_transform(vector_data)
mushroom_classes=le.fit_transform(mushroom_classes)
## Restore data matrix 
mushroom_data=np.reshape(vector_encoded,(mushroom_data.shape[0] , mushroom_data.shape[1]))
## Delete 11th attribute (9th column)
mushroom_data_21at= np.delete(mushroom_data,(9), axis = 1)
## Let 5% of data for prediction
X_training_test_data, X_prediction_data, y_training_test_data, y_prediction_data = train_test_split(mushroom_data, mushroom_classes, test_size=0.05, random_state=0)

print(X_training_test_data)
print(y_training_test_data)

"""## Data preparation"""

## Separate data set into trainig data (70%) and testing data (30%)
## Generate always the same data partition
X_train, X_test, y_train, y_test = train_test_split(X_training_test_data, y_training_test_data, test_size=0.30, random_state=0)
print(len(X_train))
print(len(y_train))
print(len(X_test))
print(len(y_test))
print(y_test)

"""## Training"""

def training_kNN(k, X_train, y_train, X_test):
  ## Define classifier, gets k parameter
  classifier = KNeighborsClassifier(n_neighbors=k)
  ## Train classifier with training data and their respective classes 
  classifier.fit(X_train, y_train)
  ## Validate predictive power of classifier with testing data
  y_predict=classifier.predict(X_test)
  return(y_predict, classifier)

training_kNN(1, X_train, y_train, X_test)

"""## Validation"""

def validation_kNN(k, X_train, y_train, X_test, y_test):
  classifier=training_kNN(k, X_train, y_train, X_test)[1]
  y_predict=training_kNN(k, X_train, y_train, X_test)[0]
  ## Validation scores
  print("Accuracy: {}".format(accuracy_score(y_test, y_predict))) ## ver si los datos est√°n balanceados
  print("Precision: {}".format(precision_score(y_test, y_predict, average="macro")))
  print("Recall: {}".format(recall_score(y_test, y_predict, average="macro")))
  print("F-score: {}".format(f1_score(y_test, y_predict, average="macro")))

  ## Class names
  target_names = ['Edible', 'Poisonous']

  ## Classification report
  print(classification_report(y_test, y_predict, target_names=target_names))
  ## Plot confusion matrix
  fig = plt.figure( )
  fig=plot_confusion_matrix(classifier, X_test, y_test, cmap=plt.cm.Blues, 
                        display_labels=target_names)
  plt.savefig(f'Confusion_matrix_k{k}.pdf')
  plt.show()

  ## Reduce data dimensions 
  X_test_embedded = TSNE(n_components=2).fit_transform(X_test)
  X_test_embedded.shape

  ## Scatterplot of testing data
  ## Create labels
  y_test_str=[]
  for i in y_test:
    ## First instance is poisonous
    if i==mushroom_classes[0]:
      y_test_str.append('Poisonous')
    else:
      y_test_str.append('Edible')
  fig = plt.figure( )
  tsne_result_df = pd.DataFrame({'tsne_1': X_test_embedded[:,0], 'tsne_2': X_test_embedded[:,1], 'label': y_test_str})
  sns.scatterplot(x='tsne_1', y='tsne_2', hue='label', data=tsne_result_df)
  plt.savefig(f'Scatterplot_testing_data_k{k}.pdf')
  plt.show()

  ## Scatterplot of predicted testing data
  y_predict_str=[]
  for i in y_predict:
    ## First instance is poisonous
    if i==mushroom_classes[0]:
      y_predict_str.append('Poisonous')
    else:
      y_predict_str.append('Edible')
  fig = plt.figure( )
  tsne_result_df = pd.DataFrame({'tsne_1': X_test_embedded[:,0], 'tsne_2': X_test_embedded[:,1], 'label': y_predict_str})
  sns.scatterplot(x='tsne_1', y='tsne_2', hue='label', data=tsne_result_df)
  plt.savefig(f'Scatterplot__predicted_data_k{k}.pdf')
  plt.show()

validation_kNN(1, X_train, y_train, X_test, y_test)

"""## Predict"""

def predict_data(k, x_train, y_train, X_prediction_data):
  # Get classifier
  classifier = training_kNN(k, x_train, y_train, X_prediction_data)[1]
  # Predict values
  predictions = classifier.predict(X_prediction_data)
  # Predicted-values associated probablities
  probabs = classifier.predict_proba(X_prediction_data)
  # Predicted-values neighbors
  neighbors = classifier.kneighbors(X_prediction_data)
  # Store results in dictionary
  results = {"Predictions" : predictions, "Probabilities" : probabs, "Neighbors" : neighbors}
  return (results)

# Predict with 5% of original data
k = 5
results = predict_data(k, X_train, y_train, X_prediction_data)
# Predictions
print(results["Predictions"])
# Probabilities are really strong
unique_probabs = set([x for x in results["Predictions"]])
print(f"Probabilities associated to model: {unique_probabs}")

def compare_predictions(k_values, x_train, y_train, X_prediction_data):
  # Iterate over k values
  for i in k_values:
    # Get prediction results
    results = predict_data(i, x_train, y_train, X_prediction_data)
    predictions = set([x for x in results["Predictions"]])
    
    print(results["Probabilities"])

compare_predictions([1,3,5,7,11], X_train, y_train, X_prediction_data)